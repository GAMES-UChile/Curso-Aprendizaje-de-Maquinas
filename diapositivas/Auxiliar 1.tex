\documentclass[handout, 9pt]{beamer}

\input{preambuloBeamer}
\usetheme{simple}
\usepackage[bb=boondox]{mathalfa}

\newcommand{\expect}{\mathop{\mathbb{E}}\nolimits}
\title{Auxiliar 1: selección de modelos}
\subtitle{MA5204 Aprendizaje de Máquinas}
\date{\today}
\author{Arie Wortsman, Nelson Moreno, Víctor Faragi,\\ Francisco Vásquez, Fernando Fêtis.} 
\titlegraphic{
\begin{figure}[htp] 
    \centering
        \includegraphics[width=0.15\textwidth]{../img/Uchile.pdf}% 
\end{figure}
}
\institute{Departamento de ingeniería matemática\\Universidad de Chile}

\begin{document}
\begin{frame}
  \titlepage
\end{frame}



%Problema de regresión.
\begin{frame}{Descomposición sesgo-varianza}

Se asumirá lo siguiente para un problema de regresión:

\begin{itemize}
	\item $\datos=\{(x_i,y_i)\}_{i=1}^N\subset\R ^M\times\R$ conjunto de observaciones.
	\item cada observación es generada por $y=f(x)+\epsilon$ donde $f$ es una función desconocida y $\epsilon$ es una v.a. de \textbf{media nula} y $\text{Var}(\epsilon)=\sigma^2$.
\end{itemize}

	
\begin{definition}
	Sea $\hat{f}(\cdot|\datos)$ un \textbf{estimador de $f$} determinado a partir de $\datos$, entonces, para una \textbf{nueva observación} $(x_0,y_0)$ se tienen las siguientes definiciones:
	
	\begin{itemize}
		\item Error de generalización: $\E_\datos\left((y_0-\hat{f}(x_0|\datos))^2\right)$.
		\item Sesgo del estimador de $f(x_0)$:
		\begin{equation*}
			\text{Bias}(\hat{f}(x_0|\datos)):= \E_\datos(\hat{f}(x_0|\datos)) - f(x_0) = \E_\datos(\hat{f}\left(x_0|\datos) - f(x_0)\right)
		\end{equation*}
		\item Varianza del estimador: $\text{Var}(\hat{f}(x_0|\datos)) := \E_\datos\left(\left(\hat{f}(x_0|\datos)-\E_\datos(\hat{f}(x_0|\datos))\right)^2\right)$.
	\end{itemize}
\end{definition}

\end{frame}

\begin{frame}{Descomposición sesgo-varianza}

\begin{figure}
\centering
	\includegraphics[scale=0.2]{../img_auxs/bias-variance.png}
\end{figure}

\end{frame}



\begin{frame}{Descomposición sesgo-varianza}

El error esperado de predicción se puede descomponer en 3 términos de acuerdo al siguiente teorema:

\begin{theorem}[descomposición sesgo-varianza] Para una nueva muestra $(x,y)$, el estimador $\hat{f}(x|\datos)$ de $f(x)$ cumple que:

\begin{equation*}
	\E\left((y-\hat{f})^2\right) = \underbrace{\left(\E(\hat{f}) - f(x)\right)^2}_{sesgo^2} + \underbrace{\E\left(\left(\hat{f}-\E(\hat{f})\right)^2\right)}_{\text{varianza estimador}} + \underbrace{\E\left(\left(\epsilon-\E(\epsilon)\right)^2\right)}_{\sigma^2 \text{ (varianza ruido)}}
\end{equation*}
	
\end{theorem}

\begin{proof}

\begin{align*}
	\E\left((y-\hat{f})^2\right) =& \E\left((f+\epsilon-\hat{f})^2\right) = \E\left(f^2+\epsilon^2+\hat{f}^2 +2f\epsilon - 2f\hat{f} - 2\epsilon \hat{f}\right)\\
	=&\left(\E^2(\hat{f})-2f\E(\hat{f}) + f^2\right) + \E\left(\hat{f}^2-2\hat{f}\E(\hat{f})+\E^2(\hat{f})\right) + \E\left(\left(\epsilon-\E(\epsilon)\right)^2\right)\\
	& - 2\E(\epsilon\hat{f})-2\E^2(\hat{f})+2\E(\hat{f})\E(\hat{f})\\
	=& \left(\E(\hat{f}) - f(x)\right)^2 + \E\left(\left(\hat{f}-\E(\hat{f})\right)^2\right) + \E\left(\left(\epsilon-\E(\epsilon)\right)^2\right) - 2\E(\epsilon)\E(\hat{f})\\
	= & \text{Bias}^2(\hat{f}(x|\datos)) + \text{Var}(\hat{f}(x|\datos)) + \sigma^2
\end{align*}

\end{proof} 

\end{frame}

\begin{frame}{Descomposición sesgo-varianza}

\begin{figure}[h!]
\centering
	\includegraphics[scale=0.4]{../img_auxs/bv-tradeoff2.png}
\end{figure}

\end{frame}

\begin{frame}{Descomposición sesgo-varianza}

En la siguiente figura, la curva azul representa el error in-sample y la curva roja representa el error out-of-sample:

\begin{figure}[h!]
\centering
	\includegraphics[scale=0.4]{../img_auxs/bv-tradeoff1.png}
\end{figure}

\end{frame}


\begin{frame}{Validación cruzada}

Es ideal poder encontrar los hiperparámetros que entreguen el par sesgo-varianza óptimo. Como esto no se puede hacer analíticamente, una forma intuitiva de comparar distintos hiperparámetros (y modelos en general) es la validación cruzada.

\begin{itemize}
	\item Es utilizada para comparar modelos cuando hay una \textbf{cantidad considerable de datos}.
	\item $\datos$ es dividido en 2:
	\begin{itemize}
		\item \textbf{Conjunto de entrenamiento:} se utiliza para encontrar algún $\hat{\theta}$ (estimador de $\theta$).
		\item \textbf{Conjunto de validación:} se utiliza para evaluar el rendimiento out-of-sample.
	\end{itemize}
	\item El conjunto $\datos$ se particiona varias veces y luego se promedian los desempeños obtenidos en cada ciclo de entrenamiento-evaluación.
	
\end{itemize}

Los tipos de CV más comunes son:

\begin{itemize}
	\item \textbf{leave $p$ out (LpOCV):} se prueban todas las posibilidades donde se utilizan $p$ elementos para evaluar el regresor.
	\item \textbf{leave one out (LOOCV):} caso anterior con $p=1$.
\end{itemize}

También es posible particionar $\datos$ en 3 conjuntos: entrenamiento, validación y testeo. Esto permite obtener una \textbf{mejor estimación del error de generalización}.
	
\end{frame}

\begin{frame}{Criterio de información de Akaike (AIC)}

Cuando no existen suficientes datos, no es buena aproximación utilizar CV para comparar el rendimiento de distintos modelos (indexados por $\theta\in\R^d$). Para estos casos, se puede realizar una \textbf{corrección a las verosimilitudes de los parámetros}.

\begin{itemize}
	\item La verosimilitud $L(\theta)=p(\datos|\theta)$ es la probabilidad de que el parámetro $\theta$ haya generado los datos $\datos$.
	\item Entonces $\E_x(l(\theta|x)))$ representa la verosimilitud esperada sobre todo el espacio muestral $\Omega$, es decir, la probabilidad de que el modelo $\theta$ genere $\Omega$.
	\item Por lo tanto, lo ideal es encontrar el $\theta_0$ que la maximice.
	\item Dado que solo se cuenta con un conjunto de entrenamiento $\datos=\{x_i\}_{i=1}^N$ y no con $\Omega$ completo, no es posible calcular $\E_x$.
	\item Se puede aproximar $\E_x(l(\theta|x)))$ mediante la verosimilitud sobre $\datos$.
\end{itemize}
	
\end{frame}

\begin{frame}{Criterio de información de Akaike (AIC)}

Una vez elegido el EMV $\hat{\theta}=\argmax_{\theta\in\Theta} l(\theta|\datos)$ no se tiene la seguridad de que dicha verosimilitud se mantenga sobre otras observaciones (i.e., al generalizar sobre $\Omega$). \textbf{AIC busca corregir la estimación $l(\theta)$ de la verosimilitud global}. Por lo anterior, se define lo siguiente:

\begin{itemize}
	\item \textbf{Riesgo empírico:} $R_\datos(\hat{\theta})=-\hat{l}$, donde $\hat{l}=l(\hat{\theta}|\datos)$ es la log-verosimilitud del EMV.
	\item \textbf{Riesgo real:} $R(\hat{\theta})=-\E_\datos(N\cdot \E_x(l(\hat{\theta}|x)))$, donde $\E_x(l(\hat{\theta}|x))$ corresponde a la log-verosimilitud de $\hat{\theta}$ sobre todo el espacio muestral $\Omega$.
\end{itemize}
	
Lo que verdaderamente se busca minimizar es el riesgo real ya que se busca el modelo qué más probablemente genere todas las muestras (i.e., el EMV sobre $\Omega$).\\

Si el riesgo empírico se ve como un estimador del riesgo real, AIC busca corregir dicha estimación, por lo que \textbf{AIC es un estimador insesgado del riesgo real}.
	
\end{frame}

\begin{frame}{Criterio de información de Akaike (AIC)}
	\begin{itemize}
		\item Para que $\overline{\mathcal{R}}(\hat{\theta})$ sea un estimador insesgado del riesgo real $R(\hat{\theta})$ debe cumplirse que $\E(\overline{\mathcal{R}}(\hat{\theta}))=R(\hat{\theta})$, es decir, que en promedio el estadístico estime el riesgo real.
		\item El sesgo del riesgo empírico $R_\datos(\hat{\theta})$ como estimador del riesgo real $R(\hat{\theta})$ viene dado por $\E(R_\datos(\hat{\theta}))-R(\hat{\theta})$.
		\item Utilizando aproximaciones de Taylor de 2º orden sobre el riesgo real y el riesgo empírico se prueba que $\E(R_\datos(\hat{\theta})) - R(\hat{\theta}) \approx -d$ ($d$ dimensión de $\theta$).
		\item Por lo tanto, por linealidad de la esperanza, $R_\datos(\hat{\theta})+d$ es un \textbf{estimador insesgado del riesgo real}.
	\end{itemize}
	
\begin{definition}[AIC]
	Sea $M$ un modelo $d$-paramétrico $\{p_\theta:\theta\in\Theta\subset\R^d\}$ y $\datos=(x_i)_{i=1}^N$ observaciones. El AIC del modelo $M$ (c/r a $\datos$) se define como
	
	\begin{equation*}
		AIC(M,\datos):=2d-2\log\left(\hat{L}(\datos)\right),
	\end{equation*}
donde $\hat{L}(\datos) = \prod_{i=1}^N p(x_i|\hat{\theta})$ para el EMV $\hat{\theta} = \argmax_{\theta\in\Theta} L(\theta|\datos)$.
\end{definition}
\end{frame}


\begin{frame}{Criterio de información de Akaike (AIC)}

\begin{itemize}
	\item Se busca elegir el modelo que entregue el menor riesgo real, por lo que se selecciona el modelo que presente la menor AIC.
	\item AIC penaliza la complejidad del modelo (dada por el número de parámetros).
	\item Para poder utilizar las aproximaciones de Taylor con igualdad, es necesario que $\datos$ sea infinito. Dado que esto en general no se tiene, se puede nuevamente corregir el estimador:
	\begin{equation*}
		AICc(M,\datos) := AIC(M,\datos) + \frac{2d(d+1)}{N-d-1}
	\end{equation*}
\end{itemize}
	
\end{frame}

\begin{frame}{Criterio de información bayesiano (BIC)}

Para un problema de selección de modelos, supóngase lo siguiente:

\begin{itemize}
	\item $\mathcal{M}$ es una familia de modelos.
	\item $p(m)$ es un prior sobre cada modelo $m\in\mathcal{M}$.
\end{itemize}

BIC elige al mejor modelo como aquel que maximice la posterior dada por


\begin{equation*}
	p(m|\datos)=\frac{p(\datos|m)p(m)}{p(\datos)}\propto p(\datos|m)p(m).
\end{equation*}

De forma análoga a AIC, se aproxima la verosimilitud del modelo $p(\datos|m)$ probando que la posterior $p(m|\datos)$ es independiente del prior. Dicha aproximación lleva a la siguiente definición:

\begin{definition}[BIC]
	Sea $M$ un modelo $d$-paramétrico $\{p_\theta:\theta\in\Theta\subset\R^d\}$ y $\datos=(x_i)_{i=1}^N$ observaciones. El BIC del modelo $M$ (c/r a $\datos$) se define como	
	\begin{equation*}
		BIC(M,\datos):= d\cdot\log(N) - 2\log\left(\hat{L}(\datos)\right)
	\end{equation*}
	
	Donde nuevamente $\hat{L}(\datos)$ corresponde a la verosimilitud del EMV asociado a $\datos$.
\end{definition}

\end{frame}

\begin{frame}{Criterio de información bayesiano (BIC)}

\begin{itemize}
	\item Se busca elegir el modelo que entregue la mayor posterior $p(m|\datos)$, por lo que se selecciona el modelo que presente el menor $BIC= d\cdot\log(N) - 2\log\hat{L}(\datos)$.
	\item Al igual que $AIC=2d-2\log\hat{L}(\datos)$, BIC penaliza la flexibilidad del modelo.
	\item \textbf{Teorema de Stone-Shao:} minimizar el AIC es asintóticamente equivalente a realizar LOOCV. Por otra parte, minimizar el BIC es asintóticamente equivalente a realizar leave $p$ out cross validation para

\begin{equation*}
	p=\left\lfloor N\left(1-\frac{1}{\log(N)-1}\right)\right\rfloor
\end{equation*}
\end{itemize}
	
\end{frame}

\begin{frame}{AIC y BIC para el modelo lineal con ruido aditivo gaussiano}

\begin{itemize}
	\item Se considera el modelo lineal generativo usual $y = \theta^\top \tilde{x} + \epsilon$ con $\epsilon\sim\cN(0,\sigma^2)$.
	\item Las observaciones $(x,y)$ vienen dadas por la distribución  $y|x \sim \cN(y;c^\top x,\sigma^2)$.
\end{itemize}

Por lo tanto, si $\hat{\theta}$ y $\hat{\sigma}^2$ son los EMV asociados al conjunto de entrenamiento $\datos=(x_i)_{i=1}^N$, la máxima log-verosimilitud viene dada por:

\begin{equation*}
	\hat{l}(\datos) = -\frac{N}{2}\log(2\pi) - \frac{N}{2}\log(\hat{\sigma}^2) - N = C(N)- \frac{N}{2}\log\left(\frac{1}{N}\text{RSS}(\datos)\right)
\end{equation*}	

Donde $\text{RSS}(\datos) := \sum_{i=1}^N \left(y_i - c^\top x_i\right)^2$ y $C(N)$ es una constante independiente del modelo por lo que puede ser omitida en la comparación de modelos. Por lo tanto, para el modelo lineal gaussiano:

\begin{itemize}
	\item $AIC=2d-N\log(\frac{1}{N}\text{RSS}(\datos))$
	\item $BIC = d\log(N) - N\log(\frac{1}{N}\text{RSS}(\datos))$
\end{itemize}

	
\end{frame}

\end{document}
